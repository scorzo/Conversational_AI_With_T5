
# Conversational AI with T5

## Summary
This project demonstrates the implementation of a short-term conversational memory using Hugging Face's Transformers library and the `google/flan-t5-base` model for generating responses in a conversational context.

## Usage
1. Install the required libraries by running the first cell which includes `!pip install transformers`.
2. Execute the cells in order to:
   - Import necessary libraries.
   - Load the `google/flan-t5-base` model and tokenizer.
   - Define a function for generating responses using the model.
   - Run a simple conversational loop that takes user input and generates responses based on the conversation history.

To interact with the AI, simply input your text when prompted. Type 'quit' to exit the conversation loop.
